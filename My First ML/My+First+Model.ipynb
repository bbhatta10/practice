{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "345c8ee7-a61f-4508-bbe7-f95c5979b89e",
   "metadata": {},
   "source": [
    "###  Breast Cancer Prediction Model Using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca2b56-a660-4080-a4cb-dab3ca2e3ab0",
   "metadata": {},
   "source": [
    "#### Import Library Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ee6b4a8-a09d-4e4c-afe5-55083c968d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns   \n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "df = pd.read_csv('Breast_cancer_data.csv')\n",
    "# print(df )\n",
    "\n",
    "\n",
    "# 'Dataset Overview and Basic Statistics'\n",
    "# df.info()\n",
    "df.describe()\n",
    "\n",
    "# df.isnull().sum()   \n",
    "# print(df.isnull().sum())\n",
    "# df.duplicated().sum()   \n",
    "print(df.duplicated().sum())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cff266-4d3b-481a-8f1b-57b60eeb24c2",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "#### 1️⃣ Importing Required Libraries\n",
    "- `import numpy as np`  \n",
    "  - Imports the **NumPy** library, which is used for numerical computations (arrays, matrices, mathematical operations).  \n",
    "\n",
    "- `import pandas as pd`  \n",
    "  - Imports the **Pandas** library, which is used for data manipulation and analysis (handling datasets, DataFrames, and Series).  \n",
    "\n",
    "#### 2️⃣ Ignoring Warnings\n",
    "- `import warnings`  \n",
    "  - Imports the **warnings** module, which manages warning messages in Python.  \n",
    "\n",
    "- `warnings.filterwarnings(\"ignore\")`  \n",
    "  - Suppresses **all warnings**, preventing unnecessary warning messages from appearing in the output.  \n",
    "  - Useful to keep the output clean while running machine learning models.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f84d4e-336e-495f-9f65-8ae496bd90d1",
   "metadata": {},
   "source": [
    "#### Load The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e2273e-10f0-45d9-95c9-3ea648885bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Breast_cancer_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc4ef2-15a6-417c-a2cb-6bb7a78459f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e613bc10-dbb6-4bbc-849c-35202b43f6bb",
   "metadata": {},
   "source": [
    "### Explanation of `df = pd.read_csv(\"Breast_cancer_data.csv\")`\n",
    "\n",
    "#### 1️⃣ What Does This Code Do?\n",
    "- Reads the **CSV (Comma-Separated Values) file** named `\"Breast_cancer_data.csv\"`.  \n",
    "- Loads the dataset into a **Pandas DataFrame (`df`)** for further analysis and processing.  \n",
    "\n",
    "#### 2️⃣ Breakdown of Each Part\n",
    "- **`pd.read_csv(...)`**  \n",
    "  - A function from the **Pandas** library that reads a CSV file and converts it into a structured **DataFrame**.  \n",
    "- **`\"Breast_cancer_data.csv\"`**  \n",
    "  - The **name of the dataset file** (it should be in the same directory as the script, or provide the full file path).  \n",
    "- **`df` (DataFrame)**  \n",
    "  - Stores the dataset in a structured table format, where:  \n",
    "    - **Rows** = Data samples (patients)  \n",
    "    - **Columns** = Features (e.g., mean_radius, mean_texture, diagnosis, etc.)  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b8c5dc-7b18-457b-ac73-380d78fcfe64",
   "metadata": {},
   "source": [
    "#### Dataset Overview And Statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce22d0-7d98-4c16-a37a-4de19b35d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28d9e30-a8f8-42ab-9fd8-69ef320583e3",
   "metadata": {},
   "source": [
    "### Explanation of `df.info()`\n",
    "\n",
    "#### 1️⃣ What Does This Code Do?\n",
    "- Displays **a summary of the dataset**, including:\n",
    "  - **Total number of rows and columns**.\n",
    "  - **Column names and their data types**.\n",
    "  - **Number of non-null (non-missing) values in each column**.\n",
    "  - **Memory usage of the DataFrame**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4487d39-ff85-4bfe-888f-f10f5c63f54a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893ad68c-9fba-46f2-a3ce-8928ec768dd6",
   "metadata": {},
   "source": [
    "### Explanation of `df.describe()`\n",
    "#### 1️⃣ What Does This Code Do?\n",
    "- Provides **statistical summary** of all **numerical columns** in the dataset.\n",
    "- Computes key descriptive statistics, including:\n",
    "  - **Count** → Number of non-null values.\n",
    "  - **Mean** → Average value.\n",
    "  - **Standard Deviation (std)** → Spread of the data.\n",
    "  - **Minimum (min)** → Smallest value.\n",
    "  - **Percentiles (25%, 50%, 75%)** → Quartiles of the data.\n",
    "  - **Maximum (max)** → Largest value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcf677e-9ed0-4bc6-8fa5-4ffa8e5bafd1",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319d327-be37-4892-a77c-d2a5cea1d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09750ccf-445b-4650-8f03-1a8647634fcc",
   "metadata": {},
   "source": [
    "### Explanation of `print(df.isnull().sum())`\n",
    "\n",
    "#### 1️⃣ What Does This Code Do?\n",
    "- Checks for **missing (null) values** in each column of the dataset.\n",
    "- Returns the total number of missing values per column.\n",
    "- If all values are `0`, there are **no missing values**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d67ecd-6b09-4d8e-b4e0-7803aea0e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482970e8-a7c1-4c6a-929d-61b39959d1d3",
   "metadata": {},
   "source": [
    "### Explanation of `print(df.duplicated().sum())`\n",
    "\n",
    "#### 1️⃣ What Does This Code Do?\n",
    "- Checks for **duplicate rows** in the dataset.\n",
    "- Returns the **total number of duplicate rows**.\n",
    "- If the output is `0`, there are **no duplicate records**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058e6b43-4003-4706-86c9-4d6f3a309dce",
   "metadata": {},
   "source": [
    "#### Expolatory Data Analysis And Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f0f01-6379-4464-8381-30e6207db4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d993d105-c108-4e5f-92aa-1ea40a3e8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ce857e-3f34-4840-8361-6a3bbd789446",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09265955-bae9-4919-8f99-4687a425adf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert diagnosis to categorical labels if not already done\n",
    "df['diagnosis'] = df['diagnosis'].map({1: 'Malignant', 0: 'Benign'})\n",
    "\n",
    "### 1️⃣ Count Plot - Benign vs. Malignant ###\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='diagnosis', data=df, palette=['green', 'red'])\n",
    "plt.title(\"Count of Benign vs. Malignant Cases\")\n",
    "plt.xlabel(\"Diagnosis\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f2bbce-fe14-4294-af2c-12c6b7954df5",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "#### 1️⃣ Convert `diagnosis` to Categorical Labels\n",
    "- **Purpose**: Convert numerical values in the `diagnosis` column (1 and 0) to more understandable categorical labels (\"Malignant\" and \"Benign\").\n",
    "- **`.map({1: 'Malignant', 0: 'Benign'})`**: This method maps the numeric values `1` and `0` to the strings `'Malignant'` and `'Benign'`, respectively.  \n",
    "  - `1` becomes `'Malignant'` (indicating cancerous).\n",
    "  - `0` becomes `'Benign'` (indicating non-cancerous).\n",
    "\n",
    "#### 2️⃣ Count Plot - Benign vs. Malignant Cases\n",
    "- **Purpose**: Visualize the distribution of cases (Benign vs. Malignant) in the dataset.\n",
    "- **`sns.countplot()`**: This Seaborn function creates a **count plot**, which shows the **frequency of categories** in the dataset.  \n",
    "  - **x='diagnosis'**: Plots the data according to the `diagnosis` column.\n",
    "  - **data=df**: The data is taken from the `df` DataFrame.\n",
    "  - **palette=['green', 'red']**: The color palette for the plot. `green` is used for Benign, and `red` for Malignant.\n",
    "\n",
    "#### 3️⃣ Plot Elements\n",
    "- **`plt.figure(figsize=(6, 4))`**: Specifies the size of the plot (6 inches by 4 inches).\n",
    "- **`plt.title(\"Count of Benign vs. Malignant Cases\")`**: Adds a title to the plot for clarity.\n",
    "- **`plt.xlabel(\"Diagnosis\")`**: Labels the x-axis as \"Diagnosis\", which indicates the two categories (Benign and Malignant).\n",
    "- **`plt.ylabel(\"Count\")`**: Labels the y-axis as \"Count\", indicating the number of occurrences of each category.\n",
    "- **`plt.show()`**: Displays the plot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa81eb9-7c49-4194-b1a5-49faf7b1969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2️⃣ Histogram - Distribution of a Feature (mean_radius) ###\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df['mean_radius'], bins=30, kde=True, color=\"blue\")\n",
    "plt.title(\"Distribution of Mean Radius\")\n",
    "plt.xlabel(\"Mean Radius\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd670930-a829-465c-b647-6837626b1749",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "#### 1️⃣ Histogram - Distribution of a Feature (`mean_radius`)\n",
    "- **Purpose**: Visualize the distribution of the `mean_radius` feature in the dataset.\n",
    "- A **histogram** shows the frequency distribution of a continuous variable, in this case, the `mean_radius` of the tumors. \n",
    "\n",
    "#### 2️⃣ Breakdown of the Code\n",
    "\n",
    "- **`sns.histplot()`**: A Seaborn function used to create histograms.\n",
    "  - **`df['mean_radius']`**: The feature for which the histogram is being plotted (mean_radius of tumors).\n",
    "  - **`bins=30`**: Specifies the number of bins (intervals) for the histogram. It helps in controlling how granular the distribution is.\n",
    "  - **`kde=True`**: Adds a **Kernel Density Estimate (KDE)** curve on top of the histogram. This curve smooths the data to show the overall distribution more clearly.\n",
    "  - **`color=\"blue\"`**: Sets the color of the histogram bars to **blue**.\n",
    "\n",
    "#### 3️⃣ Plot Elements\n",
    "- **`plt.figure(figsize=(8, 5))`**: Sets the size of the plot (8 inches by 5 inches).\n",
    "- **`plt.title(\"Distribution of Mean Radius\")`**: Adds a title to the plot for clarity.\n",
    "- **`plt.xlabel(\"Mean Radius\")`**: Labels the x-axis as \"Mean Radius\" to represent the values of the `mean_radius` feature.\n",
    "- **`plt.ylabel(\"Frequency\")`**: Labels the y-axis as \"Frequency\", indicating the number of occurrences of each value or range of values.\n",
    "- **`plt.show()`**: Displays the histogram plot.\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ff65d2-33ab-43e1-b351-2e23e1d8cd2f",
   "metadata": {},
   "source": [
    "#### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc2ab0-de46-43fc-9926-fa0ad199369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc36d3e-fa92-4cab-839d-aa49bf589b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns = ['diagnosis'])\n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fda311-99b5-454e-93da-404c0ad8a1a3",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "#### 1️⃣ Importing `train_test_split` from `sklearn.model_selection`\n",
    "- **`from sklearn.model_selection import train_test_split`**  \n",
    "  - This imports the `train_test_split` function from the **scikit-learn** library. It is used to split the dataset into training and testing sets for machine learning models.  \n",
    "  - Helps in **model evaluation** by using separate data for training and testing to prevent overfitting.\n",
    "\n",
    "#### 2️⃣ Separating Features and Target Variables\n",
    "\n",
    "- **`X = df.drop(columns = ['diagnosis'])`**  \n",
    "  - **`X`** represents the feature matrix (input variables for the model).  \n",
    "  - `df.drop(columns = ['diagnosis'])` removes the `diagnosis` column from the dataset because it is the **target variable** (what we want to predict).\n",
    "  - The remaining columns (`mean_radius`, `mean_texture`, etc.) are used as input features.\n",
    "\n",
    "- **`y = df['diagnosis']`**  \n",
    "  - **`y`** represents the target variable (output label).  \n",
    "  - `df['diagnosis']` selects the `diagnosis` column, which contains the labels: `'Malignant'` or `'Benign'` (encoded as 1 and 0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73da2368-f7f3-4ba7-9a6b-325bfa4a48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4593d7-63a6-4277-96aa-b098c3857382",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14427b0-d9dc-472f-83cc-b694bc04514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size =0.2, random_state= 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a92dc55-de9c-4fe1-b993-a2a152a43e7f",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "#### 1️⃣ Splitting the Data into Training and Testing Sets\n",
    "- **`X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)`**  \n",
    "  - This line splits the features (`X`) and target labels (`y`) into **training** and **testing** datasets.\n",
    "  - **`train_test_split`** is used to randomly divide the data, ensuring that the model is trained on a subset of the data and evaluated on a separate unseen subset.\n",
    "\n",
    "#### 2️⃣ Parameters Breakdown\n",
    "- **`X`**: The feature matrix (input data).\n",
    "- **`y`**: The target labels (what we want to predict).\n",
    "- **`test_size=0.2`**: Specifies the proportion of the dataset to include in the test split. Here, `20%` of the data will be used for testing, and the remaining `80%` will be used for training.\n",
    "- **`random_state=42`**: Ensures the data is split the same way each time you run the code, ensuring reproducibility. Changing this value will result in a different split.\n",
    "\n",
    "#### 3️⃣ Output Variables\n",
    "- **`X_train`**: The training set for the input features.\n",
    "- **`X_test`**: The testing set for the input features.\n",
    "- **`y_train`**: The training set for the target labels.\n",
    "- **`y_test`**: The testing set for the target labels.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd121c11-4282-4895-82dd-d1ab06aba6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e20b1bb-60a1-4e44-8a2f-2b0cdbc6bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c3183-a832-4c7b-a7da-ecce059129c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cd961e-6517-4ed6-b58f-d557f4278aed",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "#### 1️⃣ Importing `LogisticRegression` from `sklearn.linear_model`\n",
    "- **`from sklearn.linear_model import LogisticRegression`**  \n",
    "  - This imports the `LogisticRegression` class from the **scikit-learn** library, which is used for creating and training logistic regression models.\n",
    "  - **Logistic Regression** is a statistical model commonly used for binary classification tasks (e.g., classifying whether a tumor is malignant or benign).\n",
    "\n",
    "#### 2️⃣ Creating and Training the Model\n",
    "\n",
    "- **`model = LogisticRegression()`**  \n",
    "  - This creates an instance of the **LogisticRegression** model. The model is now ready to be trained on the data.\n",
    "\n",
    "- **`model.fit(X_train, y_train)`**  \n",
    "  - The **`fit()`** method is used to **train the model** on the provided data.\n",
    "  - **`X_train`** is the training set of input features (the data that will be used to make predictions).\n",
    "  - **`y_train`** is the training set of target labels (the known correct answers we want the model to predict).\n",
    "  - During this step, the logistic regression algorithm learns the relationship between the input features (`X_train`) and the target labels (`y_train`), adjusting its parameters (coefficients) to minimize error.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c3cbe-3dd2-49a8-a924-4e58a2647957",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb899f-b02b-46c9-a03d-e57d98f07bcc",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "#### 1️⃣ Predicting the Target Labels for the Test Set\n",
    "- **`y_pred = model.predict(X_test)`**  \n",
    "  - This line uses the trained logistic regression model to **predict** the target labels for the test data (`X_test`).\n",
    "  - **`model.predict(X_test)`**: The `predict()` method generates predicted labels based on the features in `X_test`. These predictions represent the model's guess for whether each sample in the test set is Malignant or Benign.\n",
    "\n",
    "#### 2️⃣ Output\n",
    "- **`y_pred`**: The predicted target labels for the test set. This will be an array of **0s and 1s**, where:\n",
    "  - `1` represents **Malignant** (cancerous).\n",
    "  - `0` represents **Benign** (non-cancerous).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc29ae2-9b00-4f12-8d3d-31cd36c55579",
   "metadata": {},
   "source": [
    "#### Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5910392-aba4-49f9-83e5-f4370d8fb84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Model Accuracy \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bef2901-7122-456c-910f-8ec9b799ddbb",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "#### 1️⃣ Importing `accuracy_score` from `sklearn.metrics`\n",
    "- **`from sklearn.metrics import accuracy_score`**  \n",
    "  - This imports the `accuracy_score` function from the **scikit-learn** library.\n",
    "  - **Accuracy score** is a common metric used to evaluate classification models. It represents the proportion of correctly predicted instances (both Malignant and Benign) out of the total instances in the test set.\n",
    "\n",
    "#### 2️⃣ Calculating the Model Accuracy\n",
    "\n",
    "- **`accuracy = accuracy_score(y_test, y_pred)`**  \n",
    "  - This line calculates the **accuracy** of the model's predictions.\n",
    "  - **`y_test`**: The actual target labels (true values) from the test set.\n",
    "  - **`y_pred`**: The predicted labels generated by the model.\n",
    "  - The **accuracy score** is calculated as:\n",
    "    \\[\n",
    "    \\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Predictions}}\n",
    "    \\]\n",
    "  - It returns a value between 0 and 1, where `1.0` indicates perfect accuracy (all predictions are correct), and `0.0` indicates no correct predictions.\n",
    "\n",
    "#### 3️⃣ Output\n",
    "- **`accuracy`**: The **accuracy score** of the model. It is a floating-point value between `0` and `1`. \n",
    "  - For example, if the accuracy is `0.85`, it means the model correctly predicted 85% of the test data.\n",
    "\n",
    "- **`print(\"Model Accuracy \", accuracy)`**  \n",
    "  - Displays the calculated accuracy score in the console.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c49bff-8753-4267-a8cf-6d10379b90f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test,y_pred)\n",
    "\n",
    "plt.figure(figsize = (6,4))\n",
    "plt.bar([\"training accuracy\", \"testing accuracy\"],[train_accuracy,test_accuracy], color = ['blue','green'])\n",
    "plt.ylim(0,1)\n",
    "plt.ylabel(\"Accuaracy\")\n",
    "plt.title(\"training vs testing\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6fec61-53dd-4607-9a66-2d473fa3beb9",
   "metadata": {},
   "source": [
    "### Explanation of the Code\n",
    "\n",
    "#### 1️⃣ Calculating Training and Testing Accuracy\n",
    "\n",
    "- **`train_accuracy = accuracy_score(y_train, model.predict(X_train))`**  \n",
    "  - This line calculates the accuracy of the model on the **training set**.\n",
    "  - **`model.predict(X_train)`**: Predicts the labels for the training data (`X_train`).\n",
    "  - **`y_train`**: The actual labels for the training data.\n",
    "  - **`accuracy_score(y_train, model.predict(X_train))`**: Compares the predicted values with the actual values and returns the accuracy score for the training data.\n",
    "\n",
    "- **`test_accuracy = accuracy_score(y_test, y_pred)`**  \n",
    "  - This line calculates the accuracy of the model on the **test set**.\n",
    "  - **`y_pred`**: The predicted labels for the test data (`X_test`), which were calculated earlier.\n",
    "  - **`accuracy_score(y_test, y_pred)`**: Compares the predicted values (`y_pred`) with the actual values (`y_test`) and returns the accuracy score for the test data.\n",
    "\n",
    "#### 2️⃣ Plotting the Accuracy Comparison\n",
    "\n",
    "- **`plt.figure(figsize=(6, 4))`**  \n",
    "  - Sets the figure size of the plot (6 inches by 4 inches).\n",
    "  \n",
    "- **`plt.bar([\"training accuracy\", \"testing accuracy\"], [train_accuracy, test_accuracy], color=['blue', 'green'])`**  \n",
    "  - Creates a **bar chart** to compare the training and testing accuracy.\n",
    "  - The x-axis labels are `\"training accuracy\"` and `\"testing accuracy\"`, representing the two types of accuracy.\n",
    "  - The y-axis values are `train_accuracy` and `test_accuracy`, which represent the respective accuracy scores.\n",
    "  - The colors for the bars are **blue** for training accuracy and **green** for testing accuracy.\n",
    "\n",
    "- **`plt.ylim(0, 1)`**  \n",
    "  - Sets the **y-axis limits** to range from 0 to 1, as accuracy values lie within this range.\n",
    "\n",
    "- **`plt.ylabel(\"Accuracy\")`**  \n",
    "  - Labels the y-axis as \"Accuracy\" to indicate that the values represent model accuracy.\n",
    "\n",
    "- **`plt.title(\"Training vs Testing\")`**  \n",
    "  - Adds a title to the plot, indicating that this graph compares the accuracy of the model on training vs. testing data.\n",
    "\n",
    "- **`plt.show()`**  \n",
    "  - Displays the bar chart.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312518e6-d4ff-45b3-94eb-b2241bfd1fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SilverFoxes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
